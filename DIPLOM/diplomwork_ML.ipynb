{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import optuna\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasRegionalSupport            1.000000\n",
       "okogu_code_1                  0.269164\n",
       "share_grants                  0.257334\n",
       "transformed_meanSum_grants    0.256736\n",
       "okfs_code_0                   0.236082\n",
       "                                ...   \n",
       "mainOkved_code_4             -0.059856\n",
       "opf_code_5                   -0.079098\n",
       "mainOkved_version            -0.111389\n",
       "minjustStatus_0              -0.114969\n",
       "okogu_code_4                 -0.178215\n",
       "Name: hasRegionalSupport, Length: 159, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Выясним есть ли корреляция с целевым признаком\n",
    "corr_matrix = data.corr(method='kendall')\n",
    "corr_matrix['hasRegionalSupport'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляции с целевым признаком нет, рассмотрим пары сильноскоррелированных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egrulStatus                           egrulStatus                             1.000000\n",
       "okogu_code                            okogu_code_1                            0.981792\n",
       "okogu_code_4                          okogu_code_3                            0.978794\n",
       "share_contracts                       transformed_meanSum_contracts           0.967945\n",
       "share_grants                          transformed_meanSum_grants              0.966411\n",
       "okfs_code_3                           okfs_code                               0.899441\n",
       "transformed_meanSum_fedSubsidies      share_fedSubsidies                      0.880486\n",
       "okfs_code_0                           okogu_code_1                            0.845291\n",
       "                                      okogu_code                              0.839811\n",
       "transformed_meanSum_contracts         transformed_incomeTotal                 0.799178\n",
       "transformed_incomeTotal               share_contracts                         0.773554\n",
       "okfs_code_3                           okogu_code_3                            0.745427\n",
       "minjustStatus_2                       minjustStatus_0                         0.739877\n",
       "okogu_code_4                          okfs_code                               0.739411\n",
       "okfs_code_3                           okogu_code_4                            0.727058\n",
       "okogu_code_3                          okfs_code                               0.724481\n",
       "statusDetail_shortName_Ликвидируется  statusDetail_shortName_Действующая      0.709590\n",
       "mainOkved_code_4                      mainOkved_code_6                        0.613887\n",
       "statusDetail_shortName_Действующая    statusDetail_shortName_Недействующая    0.599703\n",
       "minjustStatus_2                       mainOkved_code                          0.594834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['transformed_meanSum_grants','transformed_meanSum_fedSubsidies',\\\n",
    "    'transformed_meanSum_contracts','transformed_incomeTotal','okogu_code','okfs_code','minjustStatus_0',\\\n",
    "        'okogu_code_3','okfs_code_3','statusDetail_shortName_Ликвидируется','okfs_code_0','okpo'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['hasRegionalSupport']\n",
    "X = data.drop('hasRegionalSupport',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239962, 146) (239962,)\n",
      "(102842, 146) (102842,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Логическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     99549\n",
      "           1       0.00      0.00      0.00      3293\n",
      "\n",
      "    accuracy                           0.97    102842\n",
      "   macro avg       0.48      0.50      0.49    102842\n",
      "weighted avg       0.94      0.97      0.95    102842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "#print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(y_test,y_pred)))\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие метрики, думаю, получились из-за несбалансированности целевого признака.\n",
    "\n",
    "Проведем обогащение синтетическими данными через SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape before oversampling: (239962, 146)\n",
      "Class balance before oversampling: \n",
      "hasRegionalSupport\n",
      "0    232279\n",
      "1      7683\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Train shape after oversampling: (464558, 146)\n",
      "Class balance after oversampling: \n",
      "hasRegionalSupport\n",
      "0    232279\n",
      "1    232279\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Train shape before oversampling:', X_train.shape) \n",
    "print('Class balance before oversampling: \\n', y_train.value_counts(), sep='')\n",
    "print('-'*40)\n",
    "print('Train shape after oversampling:', X_train_s.shape)\n",
    "print('Class balance after oversampling: \\n', y_train_s.value_counts(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрик крайне низкое. Надо отметить, что т.к. распределение целевой переменной в тестовой выборке осталось несбалансированным, поэтому метрика accuracy может показывать себя плохо. Ориентируемся на метрику f1. Так же по условию задачи нам важно охватить как можно больше объектов класса 1, значит обращаем внимание на метрику RECALL при выборе итоговой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обучения и оценки классификаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(model):\n",
    "    # засекаем время\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    # обучаем модель \n",
    "    model.fit(X_train_s, y_train_s)\n",
    "    \n",
    "    # делаем предсказания с помощью модели\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # метрики\n",
    "    train_recall = metrics.recall_score(y_train_s,y_train_pred)\n",
    "    f1_train = metrics.f1_score(y_train_s,y_train_pred)\n",
    "    test_precision = metrics.precision_score(y_test,y_pred)\n",
    "    test_recall = metrics.recall_score(y_test,y_pred)\n",
    "    f1_test = metrics.f1_score(y_test,y_pred)\n",
    "    accuracy_test = metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    #список с метриками по моделям\n",
    "    list_model.append([str(model),test_precision,test_recall,f1_test,accuracy_test])\n",
    "    \n",
    "    # выводим отчет по метрикам и потраченному времени\n",
    "    print(f\"train: recall= {train_recall: 0.2f}, f1 = {f1_train: 0.2f}\")\n",
    "    #print(f\"test: recall= {test_recall: 0.2f}, f1 = {f1_test: 0.2f}, accuracy = {accuracy_test: 0.2f}\")\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Processed in {toc - tic: 0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список для сбора информации по основным метрикам рассмотренных ниже моделей\n",
    "list_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.84, f1 =  0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88     99549\n",
      "           1       0.08      0.54      0.14      3293\n",
      "\n",
      "    accuracy                           0.78    102842\n",
      "   macro avg       0.53      0.66      0.51    102842\n",
      "weighted avg       0.95      0.78      0.85    102842\n",
      "\n",
      "Processed in  7.1119 seconds\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression(random_state=0)\n",
    "predictor(LR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем сразу применять оптимизацию для поиска лучших параметров для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_lr(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2','none'])\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'sag'])\n",
    "    C = trial.suggest_float('C', 0.01, 1.0)\n",
    "\n",
    "    # создаем модель\n",
    "    model = LogisticRegression(penalty=penalty,\n",
    "                               solver=solver,\n",
    "                               C=C,\n",
    "                               random_state=0)\n",
    "  \n",
    "    # обучаем модель\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "    score = metrics.f1_score(y_train_s, model.predict(X_train_s))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 00:15:10,669] A new study created in memory with name: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 00:16:10,809] Trial 0 finished with value: 0.6338619964523923 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.4547967457107647}. Best is trial 0 with value: 0.6338619964523923.\n",
      "[I 2023-11-07 00:17:07,055] Trial 1 finished with value: 0.6338619964523923 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.4804302696552668}. Best is trial 0 with value: 0.6338619964523923.\n",
      "[I 2023-11-07 00:18:03,218] Trial 2 finished with value: 0.6338619964523923 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.8239562916680173}. Best is trial 0 with value: 0.6338619964523923.\n",
      "[I 2023-11-07 00:18:09,023] Trial 3 finished with value: 0.8181952238906586 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.7601891893218617}. Best is trial 3 with value: 0.8181952238906586.\n",
      "[I 2023-11-07 00:19:05,586] Trial 4 finished with value: 0.6338619964523923 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.9607470865557789}. Best is trial 3 with value: 0.8181952238906586.\n",
      "[I 2023-11-07 00:19:11,274] Trial 5 finished with value: 0.8181952238906586 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.9417710326859033}. Best is trial 3 with value: 0.8181952238906586.\n",
      "[I 2023-11-07 00:19:17,012] Trial 6 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8301064436773966}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:22,716] Trial 7 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8524748229103354}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:28,356] Trial 8 finished with value: 0.8181952238906586 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.5897124471693267}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:34,752] Trial 9 finished with value: 0.8181952238906586 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.08143243076418674}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:40,718] Trial 10 finished with value: 0.818197713488815 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.6349911094233638}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:46,486] Trial 11 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.7832317723590296}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:52,174] Trial 12 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.9750103387296885}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:19:57,913] Trial 13 finished with value: 0.818197713488815 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.7409178453030387}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:20:03,751] Trial 14 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8613163332578685}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:20:09,409] Trial 15 finished with value: 0.818197713488815 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.6452939073210376}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:20:15,573] Trial 16 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8875651648020205}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:20:21,849] Trial 17 finished with value: 0.8181994371134368 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.9955112772507992}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:21:19,163] Trial 18 finished with value: 0.6338619964523923 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.8547415143380745}. Best is trial 6 with value: 0.8181994371134368.\n",
      "[I 2023-11-07 00:21:24,968] Trial 19 finished with value: 0.818197713488815 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.7107526586771514}. Best is trial 6 with value: 0.8181994371134368.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8301064436773966}\n",
      "f1_score на обучающем наборе: 0.82\n",
      "CPU times: total: 13min 59s\n",
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr, n_trials=20)\n",
    "# выводим результаты на обучающей выборке\n",
    "\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.84, f1 =  0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88     99549\n",
      "           1       0.08      0.54      0.14      3293\n",
      "\n",
      "    accuracy                           0.78    102842\n",
      "   macro avg       0.53      0.66      0.51    102842\n",
      "weighted avg       0.95      0.78      0.85    102842\n",
      "\n",
      "Processed in  6.2792 seconds\n"
     ]
    }
   ],
   "source": [
    "LR_model_best = LogisticRegression(penalty='l2', solver='lbfgs',C=0.20, random_state=0)\n",
    "predictor(LR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Древо решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     99549\n",
      "           1       0.28      0.37      0.32      3293\n",
      "\n",
      "    accuracy                           0.95    102842\n",
      "   macro avg       0.63      0.67      0.65    102842\n",
      "weighted avg       0.96      0.95      0.95    102842\n",
      "\n",
      "Processed in  8.3259 seconds\n"
     ]
    }
   ],
   "source": [
    "DR_model = DecisionTreeClassifier(random_state=0)\n",
    "predictor(DR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_dt(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  criterion = trial.suggest_categorical('criterion',['gini','entropy'])\n",
    "  max_depth = trial.suggest_int('max_depth', 5, 10, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 5, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = DecisionTreeClassifier (criterion=criterion,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_samples_leaf=min_samples_leaf,\n",
    "                                  random_state=0)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train_s, y_train_s)\n",
    "  score = metrics.f1_score(y_train_s, model.predict(X_train_s))\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 00:21:39,669] A new study created in memory with name: DecisionTreeClassifier\n",
      "[I 2023-11-07 00:21:43,496] Trial 0 finished with value: 0.8977872022269485 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8977872022269485.\n",
      "[I 2023-11-07 00:21:47,265] Trial 1 finished with value: 0.8977671141449898 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8977872022269485.\n",
      "[I 2023-11-07 00:21:51,723] Trial 2 finished with value: 0.9206945940012335 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:21:54,626] Trial 3 finished with value: 0.882113408847159 and parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:21:59,046] Trial 4 finished with value: 0.9206458060658268 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:22:02,917] Trial 5 finished with value: 0.8977671141449898 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:22:06,035] Trial 6 finished with value: 0.882113408847159 and parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:22:09,748] Trial 7 finished with value: 0.9013757073332737 and parameters: {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:22:13,425] Trial 8 finished with value: 0.8977872022269485 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.9206945940012335.\n",
      "[I 2023-11-07 00:22:18,012] Trial 9 finished with value: 0.920768540763648 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:22,467] Trial 10 finished with value: 0.9206945940012335 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:27,110] Trial 11 finished with value: 0.9206945940012335 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:31,323] Trial 12 finished with value: 0.9118821549521099 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:35,544] Trial 13 finished with value: 0.9118821549521099 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:38,146] Trial 14 finished with value: 0.875503330978315 and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:42,265] Trial 15 finished with value: 0.91183901072874 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:46,766] Trial 16 finished with value: 0.9206945940012335 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:51,007] Trial 17 finished with value: 0.9119183902433956 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:54,434] Trial 18 finished with value: 0.8842449856237226 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.920768540763648.\n",
      "[I 2023-11-07 00:22:58,886] Trial 19 finished with value: 0.9206945940012335 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.920768540763648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 3}\n",
      "f1_score на обучающем наборе: 0.92\n",
      "CPU times: total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"DecisionTreeClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_dt, n_trials=20)\n",
    "\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     99549\n",
      "           1       0.28      0.37      0.32      3293\n",
      "\n",
      "    accuracy                           0.95    102842\n",
      "   macro avg       0.63      0.67      0.65    102842\n",
      "weighted avg       0.96      0.95      0.95    102842\n",
      "\n",
      "Processed in  8.1762 seconds\n"
     ]
    }
   ],
   "source": [
    "DR_model_best = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=2,random_state=0)\n",
    "predictor(DR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     99549\n",
      "           1       0.40      0.30      0.34      3293\n",
      "\n",
      "    accuracy                           0.96    102842\n",
      "   macro avg       0.69      0.64      0.66    102842\n",
      "weighted avg       0.96      0.96      0.96    102842\n",
      "\n",
      "Processed in  57.6805 seconds\n"
     ]
    }
   ],
   "source": [
    "BC_model = BaggingClassifier(random_state=0)\n",
    "predictor(BC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     99549\n",
      "           1       0.46      0.28      0.35      3293\n",
      "\n",
      "    accuracy                           0.97    102842\n",
      "   macro avg       0.72      0.64      0.67    102842\n",
      "weighted avg       0.96      0.97      0.96    102842\n",
      "\n",
      "Processed in  85.0665 seconds\n"
     ]
    }
   ],
   "source": [
    "RFC_model = RandomForestClassifier(random_state=0)\n",
    "predictor(RFC_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 300, 50)\n",
    "  max_depth = trial.suggest_int('max_depth', 5, 10, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 5, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                 max_depth=max_depth,\n",
    "                                 min_samples_leaf=min_samples_leaf,\n",
    "                                 random_state=0)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train_s, y_train_s)\n",
    "  score = metrics.f1_score(y_train_s, model.predict(X_train_s))\n",
    "\n",
    "  return score\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 00:25:29,892] A new study created in memory with name: RandomForestClassifier\n",
      "[I 2023-11-07 00:26:06,133] Trial 0 finished with value: 0.920476037202766 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.920476037202766.\n",
      "[I 2023-11-07 00:27:04,998] Trial 1 finished with value: 0.9094820626909423 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.920476037202766.\n",
      "[I 2023-11-07 00:28:18,795] Trial 2 finished with value: 0.9216258739787805 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:28:41,962] Trial 3 finished with value: 0.8965444023481411 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:29:31,870] Trial 4 finished with value: 0.9159836108741218 and parameters: {'n_estimators': 150, 'max_depth': 9, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:30:27,949] Trial 5 finished with value: 0.892144380763146 and parameters: {'n_estimators': 250, 'max_depth': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:31:24,646] Trial 6 finished with value: 0.8923152532913506 and parameters: {'n_estimators': 250, 'max_depth': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:33:10,834] Trial 7 finished with value: 0.921562936415796 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:33:33,753] Trial 8 finished with value: 0.896304301386044 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9216258739787805.\n",
      "[I 2023-11-07 00:34:46,496] Trial 9 finished with value: 0.9068402020940165 and parameters: {'n_estimators': 250, 'max_depth': 8, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.9216258739787805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 4}\n",
      "f1_score на обучающем наборе: 0.92\n",
      "CPU times: total: 9min 12s\n",
      "Wall time: 9min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=10)\n",
    "\n",
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     99549\n",
      "           1       0.46      0.28      0.35      3293\n",
      "\n",
      "    accuracy                           0.97    102842\n",
      "   macro avg       0.72      0.64      0.67    102842\n",
      "weighted avg       0.96      0.97      0.96    102842\n",
      "\n",
      "Processed in  82.7265 seconds\n"
     ]
    }
   ],
   "source": [
    "RFC_model_best = RandomForestClassifier(**study.best_params,random_state=0)\n",
    "predictor(RFC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Дополнительные деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.96, f1 =  0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94     99549\n",
      "           1       0.16      0.57      0.25      3293\n",
      "\n",
      "    accuracy                           0.89    102842\n",
      "   macro avg       0.57      0.74      0.60    102842\n",
      "weighted avg       0.96      0.89      0.92    102842\n",
      "\n",
      "Processed in  124.6071 seconds\n"
     ]
    }
   ],
   "source": [
    "ETC_model = ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_leaf=5,random_state=0)\n",
    "predictor(ETC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Адаптивный бустинг (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.92, f1 =  0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94     99549\n",
      "           1       0.17      0.59      0.27      3293\n",
      "\n",
      "    accuracy                           0.90    102842\n",
      "   macro avg       0.58      0.75      0.61    102842\n",
      "weighted avg       0.96      0.90      0.92    102842\n",
      "\n",
      "Processed in  48.1124 seconds\n"
     ]
    }
   ],
   "source": [
    "ABC_model = AdaBoostClassifier(learning_rate=0.5,random_state=0)\n",
    "predictor(ABC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Градиентный бустинг (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.93, f1 =  0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     99549\n",
      "           1       0.20      0.59      0.30      3293\n",
      "\n",
      "    accuracy                           0.91    102842\n",
      "   macro avg       0.59      0.75      0.63    102842\n",
      "weighted avg       0.96      0.91      0.93    102842\n",
      "\n",
      "Processed in  142.6401 seconds\n"
     ]
    }
   ],
   "source": [
    "GBC_model = GradientBoostingClassifier(learning_rate=0.1,random_state=0)\n",
    "predictor(GBC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Экстремальное повышение градиента (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.97, f1 =  0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     99549\n",
      "           1       0.40      0.40      0.40      3293\n",
      "\n",
      "    accuracy                           0.96    102842\n",
      "   macro avg       0.69      0.69      0.69    102842\n",
      "weighted avg       0.96      0.96      0.96    102842\n",
      "\n",
      "Processed in  9.3049 seconds\n"
     ]
    }
   ],
   "source": [
    "XGB_model = XGBClassifier(random_state=0)\n",
    "predictor(XGB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Повышение градиента на основе гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.97, f1 =  0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     99549\n",
      "           1       0.32      0.49      0.39      3293\n",
      "\n",
      "    accuracy                           0.95    102842\n",
      "   macro avg       0.65      0.73      0.68    102842\n",
      "weighted avg       0.96      0.95      0.95    102842\n",
      "\n",
      "Processed in  16.7821 seconds\n"
     ]
    }
   ],
   "source": [
    "XGBC_model = HistGradientBoostingClassifier(learning_rate=0.1,random_state=0)\n",
    "predictor(XGBC_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  learning_rate = trial.suggest_float('learning_rate', 0.1, 1)\n",
    "  max_depth = trial.suggest_int('max_depth', 5, 10, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 15, 25, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = HistGradientBoostingClassifier (learning_rate=learning_rate,\n",
    "                                 max_depth=max_depth,\n",
    "                                 min_samples_leaf=min_samples_leaf,\n",
    "                                 random_state=0)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train_s, y_train_s)\n",
    "  score = metrics.f1_score(y_train_s, model.predict(X_train_s))\n",
    "\n",
    "  return score\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 00:41:50,802] A new study created in memory with name: HistGradientBoostingClassifier\n",
      "[I 2023-11-07 00:42:03,031] Trial 0 finished with value: 0.9661504092110068 and parameters: {'learning_rate': 0.1970760271321534, 'max_depth': 5, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.9661504092110068.\n",
      "[I 2023-11-07 00:42:09,146] Trial 1 finished with value: 0.9623391219696693 and parameters: {'learning_rate': 0.8620462375726238, 'max_depth': 8, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.9661504092110068.\n",
      "[I 2023-11-07 00:42:16,833] Trial 2 finished with value: 0.9742678379246906 and parameters: {'learning_rate': 0.6176284879142232, 'max_depth': 7, 'min_samples_leaf': 25}. Best is trial 2 with value: 0.9742678379246906.\n",
      "[I 2023-11-07 00:42:22,272] Trial 3 finished with value: 0.9669610490195024 and parameters: {'learning_rate': 0.6647396792332775, 'max_depth': 10, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.9742678379246906.\n",
      "[I 2023-11-07 00:42:32,387] Trial 4 finished with value: 0.9728389850584268 and parameters: {'learning_rate': 0.305205357697531, 'max_depth': 7, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.9742678379246906.\n",
      "[I 2023-11-07 00:42:45,858] Trial 5 finished with value: 0.9701474508856543 and parameters: {'learning_rate': 0.1395692292367786, 'max_depth': 9, 'min_samples_leaf': 16}. Best is trial 2 with value: 0.9742678379246906.\n",
      "[I 2023-11-07 00:42:58,142] Trial 6 finished with value: 0.9757584649041428 and parameters: {'learning_rate': 0.25480944050604853, 'max_depth': 9, 'min_samples_leaf': 23}. Best is trial 6 with value: 0.9757584649041428.\n",
      "[I 2023-11-07 00:43:03,141] Trial 7 finished with value: 0.9621439240084674 and parameters: {'learning_rate': 0.8890317003865293, 'max_depth': 9, 'min_samples_leaf': 17}. Best is trial 6 with value: 0.9757584649041428.\n",
      "[I 2023-11-07 00:43:09,127] Trial 8 finished with value: 0.9624547172360838 and parameters: {'learning_rate': 0.6921747017750455, 'max_depth': 5, 'min_samples_leaf': 21}. Best is trial 6 with value: 0.9757584649041428.\n",
      "[I 2023-11-07 00:43:15,759] Trial 9 finished with value: 0.9693803980311511 and parameters: {'learning_rate': 0.4511637958352076, 'max_depth': 10, 'min_samples_leaf': 20}. Best is trial 6 with value: 0.9757584649041428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'learning_rate': 0.25480944050604853, 'max_depth': 9, 'min_samples_leaf': 23}\n",
      "f1_score на обучающем наборе: 0.98\n",
      "CPU times: total: 6min 13s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"HistGradientBoostingClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=10)\n",
    "\n",
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.97, f1 =  0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     99549\n",
      "           1       0.39      0.43      0.41      3293\n",
      "\n",
      "    accuracy                           0.96    102842\n",
      "   macro avg       0.68      0.71      0.69    102842\n",
      "weighted avg       0.96      0.96      0.96    102842\n",
      "\n",
      "Processed in  12.6526 seconds\n"
     ]
    }
   ],
   "source": [
    "XGBC_model_best = HistGradientBoostingClassifier(**study.best_params,random_state=0)\n",
    "predictor(XGBC_model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  1.00, f1 =  0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95     99549\n",
      "           1       0.18      0.52      0.27      3293\n",
      "\n",
      "    accuracy                           0.91    102842\n",
      "   macro avg       0.58      0.72      0.61    102842\n",
      "weighted avg       0.96      0.91      0.93    102842\n",
      "\n",
      "Processed in  464.4241 seconds\n"
     ]
    }
   ],
   "source": [
    "kNN_model = sklearn.neighbors.KNeighborsClassifier(n_jobs=-1)\n",
    "predictor(kNN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный итог\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(random_state=0)</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.535682</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.782686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(random_state=0)</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.535682</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.782686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.283120</td>\n",
       "      <td>0.369268</td>\n",
       "      <td>0.320506</td>\n",
       "      <td>0.949865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.283120</td>\n",
       "      <td>0.369268</td>\n",
       "      <td>0.320506</td>\n",
       "      <td>0.949865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier(random_state=0)</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.344008</td>\n",
       "      <td>0.962953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.284239</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.966590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.284239</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.966590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier(max_depth=15, min_samples...</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.574552</td>\n",
       "      <td>0.253093</td>\n",
       "      <td>0.891416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.5, random_s...</td>\n",
       "      <td>0.172659</td>\n",
       "      <td>0.590647</td>\n",
       "      <td>0.267207</td>\n",
       "      <td>0.896268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier(random_state=0)</td>\n",
       "      <td>0.199442</td>\n",
       "      <td>0.586395</td>\n",
       "      <td>0.297649</td>\n",
       "      <td>0.911388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.397755</td>\n",
       "      <td>0.398117</td>\n",
       "      <td>0.397936</td>\n",
       "      <td>0.961426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HistGradientBoostingClassifier(random_state=0)</td>\n",
       "      <td>0.316231</td>\n",
       "      <td>0.492256</td>\n",
       "      <td>0.385081</td>\n",
       "      <td>0.949661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier(learning_rate=0...</td>\n",
       "      <td>0.386764</td>\n",
       "      <td>0.433040</td>\n",
       "      <td>0.408596</td>\n",
       "      <td>0.959861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.182393</td>\n",
       "      <td>0.517158</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.910309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  precision    recall  \\\n",
       "0                  LogisticRegression(random_state=0)   0.078108  0.535682   \n",
       "1                  LogisticRegression(random_state=0)   0.078108  0.535682   \n",
       "2              DecisionTreeClassifier(random_state=0)   0.283120  0.369268   \n",
       "3              DecisionTreeClassifier(random_state=0)   0.283120  0.369268   \n",
       "4                   BaggingClassifier(random_state=0)   0.397217  0.303371   \n",
       "5              RandomForestClassifier(random_state=0)   0.464516  0.284239   \n",
       "6              RandomForestClassifier(random_state=0)   0.464516  0.284239   \n",
       "7   ExtraTreesClassifier(max_depth=15, min_samples...   0.162292  0.574552   \n",
       "8   AdaBoostClassifier(learning_rate=0.5, random_s...   0.172659  0.590647   \n",
       "9          GradientBoostingClassifier(random_state=0)   0.199442  0.586395   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   0.397755  0.398117   \n",
       "11     HistGradientBoostingClassifier(random_state=0)   0.316231  0.492256   \n",
       "12  HistGradientBoostingClassifier(learning_rate=0...   0.386764  0.433040   \n",
       "13                    KNeighborsClassifier(n_jobs=-1)   0.182393  0.517158   \n",
       "\n",
       "          f1  accuracy  \n",
       "0   0.136337  0.782686  \n",
       "1   0.136337  0.782686  \n",
       "2   0.320506  0.949865  \n",
       "3   0.320506  0.949865  \n",
       "4   0.344008  0.962953  \n",
       "5   0.352675  0.966590  \n",
       "6   0.352675  0.966590  \n",
       "7   0.253093  0.891416  \n",
       "8   0.267207  0.896268  \n",
       "9   0.297649  0.911388  \n",
       "10  0.397936  0.961426  \n",
       "11  0.385081  0.949661  \n",
       "12  0.408596  0.959861  \n",
       "13  0.269675  0.910309  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(\n",
    "    data = list_model,\n",
    "    columns= ['model_name','precision','recall','f1','accuracy'])\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели метрик слишком малы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим ансамбли ансамблей. Выберем все модели, показавшие recall выше 0.55. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('et', ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_leaf=5,random_state=0)),\n",
    "              ('ab', AdaBoostClassifier(learning_rate=0.5,random_state=0)),\n",
    "              ('gb', GradientBoostingClassifier(learning_rate=0.1,random_state=0))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Стек оценок с итоговым классификатором (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.95, f1 =  0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96     99549\n",
      "           1       0.20      0.55      0.29      3293\n",
      "\n",
      "    accuracy                           0.92    102842\n",
      "   macro avg       0.59      0.74      0.63    102842\n",
      "weighted avg       0.96      0.92      0.93    102842\n",
      "\n",
      "Processed in  1419.6196 seconds\n"
     ]
    }
   ],
   "source": [
    "SC_model = StackingClassifier(estimators=estimators)\n",
    "predictor(SC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Жесткий классификатор голосования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.94, f1 =  0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     99549\n",
      "           1       0.19      0.59      0.29      3293\n",
      "\n",
      "    accuracy                           0.91    102842\n",
      "   macro avg       0.59      0.75      0.62    102842\n",
      "weighted avg       0.96      0.91      0.93    102842\n",
      "\n",
      "Processed in  315.3704 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "VCh_model = VotingClassifier(estimators=estimators, voting='hard')\n",
    "predictor(VCh_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Средневзвешенные вероятности (классификатор мягкого голосования)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: recall=  0.95, f1 =  0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     99549\n",
      "           1       0.19      0.59      0.29      3293\n",
      "\n",
      "    accuracy                           0.91    102842\n",
      "   macro avg       0.59      0.75      0.62    102842\n",
      "weighted avg       0.96      0.91      0.93    102842\n",
      "\n",
      "Processed in  313.8726 seconds\n"
     ]
    }
   ],
   "source": [
    "VCs_model = VotingClassifier(estimators=estimators, voting='soft')\n",
    "predictor(VCs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Подведем итоги по  всем построенным моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(random_state=0)</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.535682</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.782686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(random_state=0)</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.535682</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.782686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.283120</td>\n",
       "      <td>0.369268</td>\n",
       "      <td>0.320506</td>\n",
       "      <td>0.949865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.283120</td>\n",
       "      <td>0.369268</td>\n",
       "      <td>0.320506</td>\n",
       "      <td>0.949865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier(random_state=0)</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.344008</td>\n",
       "      <td>0.962953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.284239</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.966590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.284239</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.966590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier(max_depth=15, min_samples...</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.574552</td>\n",
       "      <td>0.253093</td>\n",
       "      <td>0.891416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.5, random_s...</td>\n",
       "      <td>0.172659</td>\n",
       "      <td>0.590647</td>\n",
       "      <td>0.267207</td>\n",
       "      <td>0.896268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier(random_state=0)</td>\n",
       "      <td>0.199442</td>\n",
       "      <td>0.586395</td>\n",
       "      <td>0.297649</td>\n",
       "      <td>0.911388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.397755</td>\n",
       "      <td>0.398117</td>\n",
       "      <td>0.397936</td>\n",
       "      <td>0.961426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HistGradientBoostingClassifier(random_state=0)</td>\n",
       "      <td>0.316231</td>\n",
       "      <td>0.492256</td>\n",
       "      <td>0.385081</td>\n",
       "      <td>0.949661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier(learning_rate=0...</td>\n",
       "      <td>0.386764</td>\n",
       "      <td>0.433040</td>\n",
       "      <td>0.408596</td>\n",
       "      <td>0.959861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.182393</td>\n",
       "      <td>0.517158</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.910309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>StackingClassifier(estimators=[('et',\\n       ...</td>\n",
       "      <td>0.201842</td>\n",
       "      <td>0.545703</td>\n",
       "      <td>0.294687</td>\n",
       "      <td>0.916357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VotingClassifier(estimators=[('et',\\n         ...</td>\n",
       "      <td>0.189702</td>\n",
       "      <td>0.588521</td>\n",
       "      <td>0.286920</td>\n",
       "      <td>0.906332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VotingClassifier(estimators=[('et',\\n         ...</td>\n",
       "      <td>0.194859</td>\n",
       "      <td>0.587003</td>\n",
       "      <td>0.292591</td>\n",
       "      <td>0.909113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  precision    recall  \\\n",
       "0                  LogisticRegression(random_state=0)   0.078108  0.535682   \n",
       "1                  LogisticRegression(random_state=0)   0.078108  0.535682   \n",
       "2              DecisionTreeClassifier(random_state=0)   0.283120  0.369268   \n",
       "3              DecisionTreeClassifier(random_state=0)   0.283120  0.369268   \n",
       "4                   BaggingClassifier(random_state=0)   0.397217  0.303371   \n",
       "5              RandomForestClassifier(random_state=0)   0.464516  0.284239   \n",
       "6              RandomForestClassifier(random_state=0)   0.464516  0.284239   \n",
       "7   ExtraTreesClassifier(max_depth=15, min_samples...   0.162292  0.574552   \n",
       "8   AdaBoostClassifier(learning_rate=0.5, random_s...   0.172659  0.590647   \n",
       "9          GradientBoostingClassifier(random_state=0)   0.199442  0.586395   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   0.397755  0.398117   \n",
       "11     HistGradientBoostingClassifier(random_state=0)   0.316231  0.492256   \n",
       "12  HistGradientBoostingClassifier(learning_rate=0...   0.386764  0.433040   \n",
       "13                    KNeighborsClassifier(n_jobs=-1)   0.182393  0.517158   \n",
       "14  StackingClassifier(estimators=[('et',\\n       ...   0.201842  0.545703   \n",
       "15  VotingClassifier(estimators=[('et',\\n         ...   0.189702  0.588521   \n",
       "16  VotingClassifier(estimators=[('et',\\n         ...   0.194859  0.587003   \n",
       "\n",
       "          f1  accuracy  \n",
       "0   0.136337  0.782686  \n",
       "1   0.136337  0.782686  \n",
       "2   0.320506  0.949865  \n",
       "3   0.320506  0.949865  \n",
       "4   0.344008  0.962953  \n",
       "5   0.352675  0.966590  \n",
       "6   0.352675  0.966590  \n",
       "7   0.253093  0.891416  \n",
       "8   0.267207  0.896268  \n",
       "9   0.297649  0.911388  \n",
       "10  0.397936  0.961426  \n",
       "11  0.385081  0.949661  \n",
       "12  0.408596  0.959861  \n",
       "13  0.269675  0.910309  \n",
       "14  0.294687  0.916357  \n",
       "15  0.286920  0.906332  \n",
       "16  0.292591  0.909113  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(\n",
    "    data = list_model,\n",
    "    columns= ['model_name','precision','recall','f1','accuracy'])\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если при обучении моделей на тренировочной выборке показатели матрик показывают хороший результат, то на тестовой выборке метрики слишком низкие из-за несбалансированности целевой переменной. Ясно, что для построения качественной модели необходимо дополнение в стартовые данные. \n",
    "\n",
    "Хорошей модели мы не получили, но для выполнения задания подготовки модели для продакшена выберем модель с большим значением метрики f1. Это модель HistGradientBoostingClassifier с подобранными гиперпараметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Производим сериализацию обученной модели\n",
    "model = pickle.dumps(XGBC_model_best)\n",
    "\n",
    "print(type(model))\n",
    "print(type(XGBC_model_best))\n",
    "\n",
    "# Сохранение выбранной обученной модели в файл pickle\n",
    "with open(\"XGBC_model_best.pkl\", \"wb\") as output:\n",
    "    pickle.dump(XGBC_model_best, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
